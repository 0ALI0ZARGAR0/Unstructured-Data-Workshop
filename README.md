# Hands-On Unstructured Data: From Logs to Semantic Search

## Workshop Overview

In this workshop, we rolled up our sleeves for a practical session. The main idea was to explore how we can work with and get insights from common types of unstructured data – specifically application logs and plain text. We used Docker to package the tools, which helped keep things consistent and manageable for everyone.

Our goals were to get a feel for these things about unstructured data:

- Setting up a basic log aggregation pipeline with Loki, Promtail, and Grafana.
- Trying out some real-time log queries using LogQL.
- Understanding the fundamentals of vector embeddings and what semantic search is all about.
- Working with a vector database (we used Qdrant) to index and search text data by its meaning.
- And, in the process, getting a bit more hands-on experience with Docker Compose.

We tried to keep the entry bar pretty reasonable, mostly assuming a bit of familiarity with Docker and the command line, along with Python.

---

## Directory Structure

We had a project structure set up with all the necessary configuration files and scripts. This included our `docker-compose.yml` to define all the services, configuration for Promtail and Grafana, a simple Python app to generate logs, and another Python script for the semantic search demonstration. This organization helped keep all the pieces of the workshop clear and accessible.

---

## Part 1: Log Management with Loki & Grafana

In the first part of our session, we focused on handling application logs. We showcased a pipeline where:

- A **Python script** acted as our simple, real-time log generator, simulating application output. This gave us a dynamic source of data to work with.
- **Docker Compose** was used to orchestrate all our services. This was key to easily spinning up the entire logging stack (our log generator, Promtail, Loki, and Grafana) with a single command, simplifying setup for everyone.
- **Promtail** played the role of the log collector. We explained its purpose was to automatically discover and forward logs from our generator to Loki. This helped attendees understand how logs from various containerized sources can be efficiently gathered.
- **Loki** served as our central log aggregation system. We highlighted its design for efficiently storing and indexing large volumes of log data without needing extensive pre-parsing, which can be very cost-effective. For attendees, this meant seeing a system built for handling modern application logs at scale.
- **Grafana** provided the interactive visualization layer. Once connected to Loki, it enabled attendees to see logs streaming in, and more importantly, to query them using **LogQL**. This demonstrated the practical benefit of searching, filtering, and beginning to analyze log data from a central dashboard, which is invaluable for monitoring application health and troubleshooting issues effectively.

---

## Part 2: Semantic Search with Qdrant

Next, we shifted our focus to exploring text data through semantic search. The key components here were:

- **Python**, along with the **`sentence-transformers` library**, where we specifically used the lightweight `all-MiniLM-L6-v2` model (A 22 million parameters Minimally Distilled Language Model). We explained that this model's role is crucial: it converts plain text (our sample words and any search queries) into rich numerical representations called vector embeddings. This process is what allows us to capture the semantic meaning of the text. Attendees learned how accessible these powerful NLP models have become for such tasks.
- **Qdrant**, which we introduced as a specialized **vector database**. Its purpose in our setup was to store the vector embeddings generated by the sentence transformer. We emphasized that Qdrant is optimized for efficiently searching through these high-dimensional vectors to find the closest matches based on similarity.

Through an interactive demo where attendees could provide search terms, they saw these terms get converted to vectors, and then witnessed Qdrant retrieve semantically similar words from the indexed dataset. This clearly highlighted how such a system moves beyond simple keyword matching to enable more intelligent and context-aware search experiences, offering a glimpse into building more intuitive applications.

---

## Cleanup

To wrap things up neatly and ensure we left our systems as they were, we demonstrated how a single command, `docker-compose down -v`, would stop all the running Docker containers. The `-v` flag was important as it also removed the named and anonymous volumes, including the one Qdrant used for storing its data. This is always a good practice after working with Dockerized environments for development or workshops.

---

## Key Concepts We Touched On

Throughout this session, we wove in several important ideas:

- We started with the concept of **Unstructured Data**, discussing how data like logs, text, and images often doesn't fit neatly into traditional, predefined database tables.
- For logs, we looked at **Log Aggregation** – the practice of collecting logs from various sources into a central place for easier analysis. In our setup, **Loki** served as our storage and indexing system, while **Promtail** was the agent responsible for shipping logs from our container to Loki.
- We got a practical taste of **LogQL**, Loki's query language, which allows users to filter, parse, and perform aggregations on logs in a way that's somewhat similar to how PromQL works for metrics.
- Moving to text, we introduced **Vector Embeddings**. We talked about these as numerical representations (vectors) of text that aim to capture its semantic meaning, allowing computers to "understand" and compare text in a more nuanced way.
- This naturally led us to **Semantic Search**, a technique that leverages these embeddings to find information based on meaning and context, going beyond simple keyword matching.
- And finally, we saw the role of a **Vector Database** like **Qdrant**, which is specially designed to efficiently store, manage, and search through these high-dimensional vector embeddings.

---

It was a nice opportunity!
